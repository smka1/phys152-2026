{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 2-D Ising Model experiment\n",
        "*(after Mehta et al.)*\n",
        "\n",
        "The states of the 2D Ising model according to their phase.\n",
        "\n",
        "The Hamiltonian for the classical Ising model is given by\n",
        "\n",
        "$$ H = -J\\sum_{\\langle ij\\rangle}S_{i}S_j,\\qquad \\qquad S_j\\in\\{\\pm 1\\} $$\n",
        "\n",
        "where the lattice site indices $i,j$ run over all nearest neighbors of a 2-D square lattice, and $J$ is some arbitrary interaction energy scale. We adopt periodic boundary conditions so that every site has 4 nearest neighbors, even at the boundaries.\n",
        "\n",
        "Onsager proved that this model undergoes a phase transition in the thermodynamic limit from an ordered ferromagnet with all spins aligned to a disordered phase at the critical temperature $T_c/J=2/\\log(1+\\sqrt{2})\\approx 2.26$. For any finite system size, this critical point is expanded to a critical region around $T_c$.\n",
        "\n",
        "For this hands-on example, we'll train a Deep Neural Network to predict whether a certain 2-D spin state configuration will result in a disordered phase (label \"0\") or ordered phase (label \"1\")."
      ],
      "metadata": {
        "id": "hNhuDaQkETLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from urllib.request import urlopen\n",
        "\n",
        "def load_data():\n",
        "\n",
        "    url_main = 'https://physics.bu.edu/~pankajm/ML-Review-Datasets/isingMC/';\n",
        "\n",
        "    # The data consists of 16*10000 samples taken in T=np.arange(0.25,4.0001,0.25):\n",
        "    data_file_name = \"Ising2DFM_reSample_L40_T=All.pkl\"\n",
        "    # The labels are obtained from the following file:\n",
        "    label_file_name = \"Ising2DFM_reSample_L40_T=All_labels.pkl\"\n",
        "\n",
        "    data = pickle.load(urlopen(url_main + data_file_name)) # pickle reads the file and returns the Python object (1D array, compressed bits)\n",
        "    data = np.unpackbits(data).reshape(-1, 1600) # Decompress array and reshape for convenience\n",
        "    data=data.astype('int')\n",
        "    data[np.where(data==0)]=-1 # map 0 state to -1 (Ising variable can take values +/-1)\n",
        "\n",
        "    #labels (convention is 1 for ordered states and 0 for disordered states)\n",
        "    labels = pickle.load(urlopen(url_main + label_file_name)) # pickle reads the file and returns the Python object (here just a 1D array with the binary labels)\n",
        "\n",
        "    print(\"Finished loading data\")\n",
        "    return data, labels\n",
        "\n",
        "data, labels = load_data()"
      ],
      "metadata": {
        "id": "iZ2xjy7Iz__v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Define a custom Dataset for the Ising model data\n",
        "class IsingDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        # Convert numpy arrays to torch tensors\n",
        "        self.features = torch.tensor(features, dtype=torch.float32)\n",
        "        # Labels should be float for BCEWithLogitsLoss and have a shape [N, 1]\n",
        "        self.labels = torch.tensor(labels, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "# Using test_size=0.2 as a common practice, adjust if needed\n",
        "X_train_ising, X_test_ising, y_train_ising, y_test_ising = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Ising training features shape: {X_train_ising.shape}, Ising training labels shape: {y_train_ising.shape}\")\n",
        "print(f\"Ising testing features shape: {X_test_ising.shape}, Ising testing labels shape: {y_test_ising.shape}\")\n",
        "\n",
        "# Create instances of the custom Dataset\n",
        "ising_train_dataset = IsingDataset(X_train_ising, y_train_ising)\n",
        "ising_test_dataset = IsingDataset(X_test_ising, y_test_ising)\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 32 # You can adjust this batch size\n",
        "ising_training_dataloader = DataLoader(ising_train_dataset, batch_size=batch_size, shuffle=True)\n",
        "ising_testing_dataloader = DataLoader(ising_test_dataset, batch_size=batch_size, shuffle=False) # No need to shuffle test data\n",
        "\n",
        "print(f\"Number of Ising training batches: {len(ising_training_dataloader)}\")\n",
        "print(f\"Number of Ising testing batches: {len(ising_testing_dataloader)}\")"
      ],
      "metadata": {
        "id": "CT7AqnBCbm-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "# define DNN model\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(1600, 160),\n",
        "    nn.ELU(),\n",
        "    nn.Linear(160, 40),\n",
        "    nn.ELU(),\n",
        "    nn.Linear(40, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 1cycle implement in Torch as OneCycleLR\n",
        "scheduler = OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=0.1,                      # Peak learning rate\n",
        "    epochs=100,                      # Total epochs\n",
        "    steps_per_epoch=len(ising_training_dataloader),  # Batches per epoch\n",
        "    pct_start=0.3,                   # 30% warmup, 70% annealing\n",
        "    anneal_strategy='cos',           # Cosine annealing\n",
        "    div_factor=25.0,                 # Initial LR = max_lr/25\n",
        "    final_div_factor=1e4             # Final LR = max_lr/10000\n",
        ")\n",
        "\n",
        "# training loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, target) in enumerate(ising_training_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # CRITICAL for 1cycle: step scheduler after each batch, not each epoch!\n",
        "        scheduler.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "v38vf0iYeqgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Ensure the model is on the correct device (CPU or GPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "all_labels = []\n",
        "all_predictions = []\n",
        "\n",
        "# Disable gradient calculations for inference\n",
        "with torch.no_grad():\n",
        "    for data, target in ising_training_dataloader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        all_predictions.extend(output.cpu().numpy())\n",
        "        all_labels.extend(target.cpu().numpy())\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "y_true = np.array(all_labels)\n",
        "y_pred_proba = np.array(all_predictions)\n",
        "\n",
        "# For binary classification with Sigmoid, output is already probability, but ensure shape is correct\n",
        "# y_pred_proba will be (N, 1), we need (N,) for roc_curve\n",
        "y_pred_proba = y_pred_proba.flatten()\n",
        "y_true = y_true.flatten()\n",
        "\n",
        "# Convert probabilities to binary predictions for accuracy calculation (e.g., threshold at 0.5)\n",
        "y_pred_binary = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = accuracy_score(y_true, y_pred_binary)\n",
        "print(f\"Accuracy on training data: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "print(\"Thresholds (first 10):\", thresholds[:10]) # Print first 10 thresholds, not all\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve for Deep Neural Network (Training Data)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x1jGFJb6ljFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deeeep Neural Network for SUSY event classification\n",
        "\n",
        "The SUSY ML dataset at UCI is sufficiently large and complex that a deep neural network is worth the effort. Smaller datasets like iris don't provide enough data variance to train the large number of model parameters in the DNN.\n",
        "\n",
        "We will use the same data loading techniques as for the multi-layer perceptron."
      ],
      "metadata": {
        "id": "S0_zn0L1nYva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "class CSVDataset(Dataset):\n",
        "    def __init__(self, csv_file, max_samples=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        if max_samples:\n",
        "            self.data = self.data.iloc[:max_samples]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        features = torch.tensor(row.iloc[1:].values, dtype=torch.float32)\n",
        "        label = torch.tensor(row.iloc[0], dtype=torch.float32)\n",
        "        return features, label\n",
        "\n",
        "# Use it with DataLoader\n",
        "#dataset = CSVDataset('https://archive.ics.uci.edu/ml/machine-learning-databases/00279/SUSY.csv.gz', 1000)\n",
        "dataset = CSVDataset('/content/drive/My Drive/Colab Notebooks/SUSY.csv.gz', 1000)\n",
        "\n",
        "# Define split ratios (80% train, 20% test)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "# Split the dataset\n",
        "train_dataset, test_dataset = random_split(\n",
        "    dataset,\n",
        "    [train_size, test_size],\n",
        "    generator=torch.Generator().manual_seed(42)  # For reproducibility\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Testing samples: {len(test_dataset)}\\n\")\n",
        "\n",
        "# DataLoaders handle batching, shuffling, and parallel loading\n",
        "training_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "testing_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "GPU9od_fn2uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define DNN model\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(18, 20),\n",
        "    nn.ELU(),\n",
        "    nn.Linear(20, 20),\n",
        "    nn.ELU(),\n",
        "    nn.Linear(20, 20),\n",
        "    nn.ELU(),\n",
        "    nn.Linear(10, 1)\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 1cycle implement in Torch as OneCycleLR\n",
        "scheduler = OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=0.1,                      # Peak learning rate\n",
        "    epochs=100,                      # Total epochs\n",
        "    steps_per_epoch=len(train_loader),  # Batches per epoch\n",
        "    pct_start=0.3,                   # 30% warmup, 70% annealing\n",
        "    anneal_strategy='cos',           # Cosine annealing\n",
        "    div_factor=25.0,                 # Initial LR = max_lr/25\n",
        "    final_div_factor=1e4             # Final LR = max_lr/10000\n",
        ")\n",
        "\n",
        "# training loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # CRITICAL for 1cycle: step scheduler after each batch, not each epoch!\n",
        "        scheduler.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "w088EU_qo5_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get predicted probabilities for the positive class\n",
        "y_pred_proba_dnn = model.predict_proba(X_train)[:, 1]\n",
        "\n",
        "# Calculate ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_train, y_pred_proba_xgb)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(thresholds)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve for Deep Neural Network')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u-dBGoLXpCHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using GPUs in Colab\n",
        "\n",
        "We now turn to an important enabler of Deep Neural Networks -- the Graphical Processing Unit (GPU), which is built for massively parallel arithmetic operations. For Machine Learning, the killer app is matrix multiplication (MatMul), which is the backbone of neural network training and inference.\n",
        "\n",
        "## Enabling GPUs in Colab\n",
        "\n",
        "To switch to a GPU-enabled runtime instance in Colab, go to the **Runtime** menu and select **Change runtime type**.\n",
        "The **T4 GPU** instance is always free for Colab Pro users; more advanced GPUs may require payment.\n",
        "We expect the T4 GPUs will be sufficient for all of our work in this course.\n",
        "\n",
        "*Change the runtime type to T4 GPU for the following hands-on work now.*\n",
        "\n",
        "Check to see if the GPU is enabled by using `torch.cuda.is_available()`. (Cuda is NVIDIA's custom software for processing on GPUs. Torch will use Cuda libraries if you ask it to do so.)"
      ],
      "metadata": {
        "id": "uOs-RncMjZP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
      ],
      "metadata": {
        "id": "YU0gRnmV9yjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The key step for GPU-enabled training is loading the model and data into the local GPU memory.\n",
        "\n",
        "We update the code for the SUSY classification here, with the correct calls to load model and data into the GPUs.\n",
        "Try benchmarking this code with a CPU runtime type vs. GPU runtime type."
      ],
      "metadata": {
        "id": "onPHAaqck3VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)  # Moves all model parameters to GPU\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Move batch to GPU\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # CRITICAL for 1cycle: step scheduler after each batch, not each epoch!\n",
        "        scheduler.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "ggHpvhyanuez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6lWoM5nCjX7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Local GPU training\n",
        "\n",
        "You can even train and use DNNs on your laptop, if it has a GPU.\n",
        "the steps will be different for Windows, Linux, and Macs.\n",
        "The new M-series Macs have powerful GPUs built in, but you should ask for `mps` instead of `cuda`.\n",
        "\n",
        "```\n",
        "device = torch.device('mps:0' if torch.mps.is_available() else 'cpu')\n",
        "print(f\"On Mac, using: {device}\")\n",
        "```"
      ],
      "metadata": {
        "id": "2TzUXpsflKjl"
      }
    }
  ]
}