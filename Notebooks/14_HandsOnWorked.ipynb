{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1FuKAitZUAXc_3Z23cIS6MKZQoiECFxAA","timestamp":1770361872809}],"authorship_tag":"ABX9TyPZdEcHgQyWIsaq1LUqaE6t"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Convolutional Neural Networks with the Galaxy10 DECaLS dataset\n","\n","## Introduction to the physics\n","\n","One long-standing challenge in observational cosmology is cataloging the huge number of sources discovered by space-based and ground-based survey telescopes. In recent years, physicists have turned to machine learning as a way of classifying large numbers of galaxies.\n","\n","In this notebook, we explore the Galaxy10 DECaLS and train a CNN to classify galaxies based on the observed images.\n","\n","The images are labeled as belonging to one of ten morphology classes (labeled manually by [Galaxy Zoo](https://www.zooniverse.org/projects/zookeeper/galaxy-zoo) volunteers!).\n","\n","The ten galaxy classes are:\n","- 0: Disturbed\n","- 1: Merging  \n","- 2: Round Smooth\n","- 3: In-between Smooth\n","- 4: Cigar Smooth\n","- 5: Barred Spiral\n","- 6: Unbarred Tight Spiral\n","- 7: Unbarred Loose Spiral\n","- 8: Edge-on (no bulge)\n","- 9: Edge-on (with bulge)\n"],"metadata":{"id":"1YHujAgrNnWy"}},{"cell_type":"code","source":["import torch\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","import h5py\n","import numpy as np\n","from pathlib import Path\n","import urllib.request\n","from PIL import Image\n","\n","# Use the Galaxy10 DECaLS dataset\n","def download_galaxy10(data_dir='./data'):\n","    \"\"\"Download Galaxy10 DECaLS dataset (2.5GB)\"\"\"\n","    data_dir = Path(data_dir)\n","    data_dir.mkdir(parents=True, exist_ok=True)\n","\n","    file_path = data_dir / 'Galaxy10_DECals.h5'\n","\n","    if file_path.exists():\n","        print(f\"Dataset already exists at {file_path}\")\n","        return file_path\n","\n","    url = \"https://zenodo.org/records/10845026/files/Galaxy10_DECals.h5\"\n","\n","    print(\"Downloading Galaxy10 DECaLS dataset (2.5GB)...\")\n","    print(\"This may take a few minutes...\")\n","\n","    urllib.request.urlretrieve(url, file_path)\n","\n","    print(f\"Download complete! Saved to {file_path}\")\n","    return file_path\n"],"metadata":{"id":"z5Tsyj5iphOR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Galaxy10Dataset(Dataset):\n","    \"\"\"\n","    Galaxy10 Dataset with 10 classes:\n","    0: Disturbed\n","    1: Merging\n","    2: Round Smooth\n","    3: In-between Smooth\n","    4: Cigar Smooth\n","    5: Barred Spiral\n","    6: Unbarred Tight Spiral\n","    7: Unbarred Loose Spiral\n","    8: Edge-on (no bulge)\n","    9: Edge-on (with bulge)\n","    \"\"\"\n","\n","    def __init__(self, h5_file, indices=None, transform=None):\n","      self.h5_file = h5_file\n","      self.transform = transform\n","\n","      with h5py.File(h5_file, 'r') as f:\n","          self.images = np.array(f['images'])\n","          self.labels = np.array(f['ans'])\n","\n","      if indices is not None:\n","          self.images = self.images[indices]\n","          self.labels = self.labels[indices]\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        image = Image.fromarray(self.images[idx].astype('uint8'))\n","        label = self.labels[idx]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label"],"metadata":{"id":"GK2aHd2fpu8Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_dataloaders(h5_file, batch_size=32, num_workers=2):\n","\n","    # Define transforms\n","    train_transform = transforms.Compose([\n","        transforms.Resize((128, 128)),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomRotation(180),\n","        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                           std=[0.229, 0.224, 0.225])\n","    ])\n","\n","    test_transform = transforms.Compose([\n","        transforms.Resize((128, 128)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                           std=[0.229, 0.224, 0.225])\n","    ])\n","\n","    with h5py.File(h5_file, 'r') as f:\n","        total_size = len(f['ans'])\n","\n","    indices = np.arange(total_size)\n","    np.random.seed(42)\n","    np.random.shuffle(indices)\n","\n","    train_size = int(0.7 * total_size)\n","    val_size = int(0.15 * total_size)\n","\n","    train_indices = indices[:train_size]\n","    val_indices = indices[train_size:train_size + val_size]\n","    test_indices = indices[train_size + val_size:]\n","\n","    train_dataset = Galaxy10Dataset(h5_file, train_indices, train_transform)\n","    val_dataset = Galaxy10Dataset(h5_file, val_indices, test_transform)\n","    test_dataset = Galaxy10Dataset(h5_file, test_indices, test_transform)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n","                             shuffle=True, num_workers=num_workers)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size,\n","                           shuffle=False, num_workers=num_workers)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size,\n","                            shuffle=False, num_workers=num_workers)\n","\n","    print(f\"Train: {len(train_dataset)} | Val: {len(val_dataset)} | Test: {len(test_dataset)}\")\n","\n","    return train_loader, val_loader, test_loader\n"],"metadata":{"id":"Ox3C-F5epzpb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch_geometric\n","from torch_geometric.nn import global_mean_pool, global_max_pool\n","\n","class GalaxyCNN(nn.Module):\n","    \"\"\"\n","    Simple CNN for galaxy classification\n","    Input: 3x128x128 images\n","    Output: 10 classes\n","    \"\"\"\n","    def __init__(self, num_classes=10):\n","        super(GalaxyCNN, self).__init__()\n","\n","        # Only 1 convolutional block\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=5, padding=2),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","            nn.MaxPool2d(4, 4)  # 64 -> 16\n","        )\n","\n","        # Global pooling\n","        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n","\n","        # Very small classifier\n","        self.fc = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(32, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.global_pool(x)\n","        x = self.fc(x)\n","        return x"],"metadata":{"id":"40nBP3SgqU3t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_one_epoch(model, train_loader, criterion, optimizer, device):\n","    \"\"\"Train for one epoch\"\"\"\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        # Forward pass\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Statistics\n","        running_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        total += labels.size(0)\n","        correct += predicted.eq(labels).sum().item()\n","\n","    epoch_loss = running_loss / len(train_loader)\n","    epoch_acc = 100. * correct / total\n","\n","    return epoch_loss, epoch_acc\n","\n","\n","def validate(model, val_loader, criterion, device):\n","    \"\"\"Validate the model\"\"\"\n","    model.eval()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images, labels = images.to(device), labels.to(device)\n","\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += labels.size(0)\n","            correct += predicted.eq(labels).sum().item()\n","\n","    val_loss = running_loss / len(val_loader)\n","    val_acc = 100. * correct / total\n","\n","    return val_loss, val_acc\n"],"metadata":{"id":"ZwGCTEfeqn3W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(num_epochs=10, batch_size=32, learning_rate=0.001):\n","    \"\"\"Complete training pipeline\"\"\"\n","\n","    # Setup\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    print(f\"Using device: {device}\")\n","\n","    # Load data\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"Loading Dataset\")\n","    print(\"=\"*60)\n","    h5_file = download_galaxy10(data_dir='./data')\n","    train_loader, val_loader, test_loader = create_dataloaders(\n","        h5_file,\n","        batch_size=batch_size,\n","        num_workers=2\n","    )\n","\n","    # Create model\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"Creating Model\")\n","    print(\"=\"*60)\n","    model = GalaxyCNN(num_classes=10).to(device)\n","    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n","\n","    # Loss and optimizer\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n","                                                     factor=0.5, patience=2)\n","\n","    # Training history\n","    train_losses = []\n","    train_accs = []\n","    val_losses = []\n","    val_accs = []\n","\n","    # Training loop\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"Training\")\n","    print(\"=\"*60)\n","\n","    best_val_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        # Train\n","        train_loss, train_acc = train_one_epoch(\n","            model, train_loader, criterion, optimizer, device\n","        )\n","\n","        # Validate\n","        val_loss, val_acc = validate(model, val_loader, criterion, device)\n","\n","        # Learning rate scheduling\n","        scheduler.step(val_loss)\n","        current_lr = optimizer.param_groups[0]['lr']\n","\n","        # Save history\n","        train_losses.append(train_loss)\n","        train_accs.append(train_acc)\n","        val_losses.append(val_loss)\n","        val_accs.append(val_acc)\n","\n","        # Print progress\n","        print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n","              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n","              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}% | \"\n","              f\"LR: {current_lr:.6f}\")\n","\n","        # Save best model\n","        if val_acc > best_val_acc:\n","            best_val_acc = val_acc\n","            torch.save(model.state_dict(), 'best_galaxy_model_no_dropout.pth')\n","            print(f\"  -> New best model saved! (Val Acc: {val_acc:.2f}%)\")\n","\n","       # Test final model\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"Testing\")\n","    print(\"=\"*60)\n","    test_loss, test_acc = validate(model, test_loader, criterion, device)\n","    print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n","\n","    # Plot training curves\n","    plot_training_curves(train_losses, val_losses, train_accs, val_accs)\n","\n","    return model, (train_losses, val_losses, train_accs, val_accs)\n"],"metadata":{"id":"a0aWmeGgqwv1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_training_curves(train_losses, val_losses, train_accs, val_accs):\n","    \"\"\"Plot training and validation curves\"\"\"\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n","\n","    # Loss\n","    ax1.plot(train_losses, label='Train Loss', marker='o')\n","    ax1.plot(val_losses, label='Val Loss', marker='s')\n","    ax1.set_xlabel('Epoch')\n","    ax1.set_ylabel('Loss')\n","    ax1.set_title('Training and Validation Loss')\n","    ax1.legend()\n","    ax1.grid(True)\n","\n","    # Accuracy\n","    ax2.plot(train_accs, label='Train Acc', marker='o')\n","    ax2.plot(val_accs, label='Val Acc', marker='s')\n","    ax2.set_xlabel('Epoch')\n","    ax2.set_ylabel('Accuracy (%)')\n","    ax2.set_title('Training and Validation Accuracy')\n","    ax2.legend()\n","    ax2.grid(True)\n","\n","    plt.tight_layout()\n","    plt.savefig('training_curves_no_dropout.png', dpi=150)\n","    print(\"\\nTraining curves saved to 'training_curves_no_dropout.png'\")\n","    plt.close()\n"],"metadata":{"id":"vrwjUEnWq_53"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"=\"*60)\n","print(\"Galaxy10 CNN Training\")\n","print(\"- No dropout (using BatchNorm for regularization)\")\n","print(\"- torch_geometric compatible structure\")\n","print(\"=\"*60)\n","\n","# Choose model type\n","# 'standard' or 'graph_style'\n","model, history = train_model(\n","    num_epochs=15,\n","    batch_size=32,\n","    learning_rate=0.001\n",")\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"Training Complete!\")\n","print(\"=\"*60)\n","print(\"Model saved to: best_galaxy_model_no_dropout.pth\")\n","print(\"Training curves saved to: training_curves_no_dropout.png\")"],"metadata":{"id":"kYFSEPErrCe_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Graph Neural Networks to classify particle decays\n","\n","# Introduction to the physics\n","\n","The Z boson typically decays into 2 particles (like electron-positron pairs), while the Higgs can decays into 4 particles (via intermediate particles like 2 Z bosons).\n","One challenge is to separate the two kinds of decays so that we can measure Higgs boson production.\n","\n","In particle physics, decay events naturally form graphs:\n","\n","- Nodes represent particles\n","- Edges represent relationships (like coming from the same parent particle)\n","\n","## Generating particle decay data\n","\n","Although there are particle physics datasets that we could use for general-purpose studies, it's convenient to simply generate the particle decays of the Z boson and Higgs boson here.\n","This allows us to control the mix of decays and get exactly the right format.\n","\n","Typical simulations use random numbers to generate random momenta for the parent particles.\n","We will write the simulation and the training models as functions so that we can mix them up later."],"metadata":{"id":"gEfdXQXPmCOO"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset\n","from torch_geometric.loader import DataLoader\n","from torch_geometric.data import Data\n","import numpy as np\n","\n","def create_simulated_decay_data(num_events=1000, decay_type='Z'):\n","    \"\"\"\n","    Physics background:\n","    - Z boson (mass ~91 GeV) decays into 2 particles (e.g., e+ e-)\n","    - Higgs boson (mass ~125 GeV) often decays into 4 particles (e.g., H -> ZZ -> 4 leptons)\n","\n","    Args:\n","        num_events: Number of decay events to generate\n","        decay_type: 'Z' (2 particles) or 'Higgs' (4 particles)\n","\n","    Returns:\n","        List of PyTorch Geometric Data objects\n","    \"\"\"\n","    data_list = []\n","\n","    for _ in range(num_events):\n","        if decay_type == 'Z':\n","            # Z decay: 2 particles back-to-back\n","            num_particles = 2\n","            y = torch.tensor([0], dtype=torch.long)  # Label: 0 for Z\n","\n","            # Simulate particle 4-momenta: [px, py, pz, energy]\n","            # Z decays show balanced momentum\n","            #  because the particles recoil against each other\n","            momentum = np.random.randn(4) * 50 + 45  # 45 GeV = mZ/2\n","            x = torch.tensor([\n","                [momentum[0], momentum[1], momentum[2], np.abs(momentum[0])],\n","                [-momentum[0], -momentum[1], -momentum[2], np.abs(momentum[0])]\n","            ], dtype=torch.float)\n","\n","            # Fully connected graph: both particles connected\n","            edge_index = torch.tensor([[0, 1], [1, 0]], dtype=torch.long)\n","\n","        else:  # Higgs\n","            # Higgs decay: 4 particles (more complex topology)\n","            num_particles = 4\n","            y = torch.tensor([1], dtype=torch.long)  # Label: 1 for Higgs\n","\n","            # Simulate 4 particles with lower individual momenta\n","            # Each Z boson from Higgs decays in turn to two leptons\n","            x = torch.tensor([\n","                np.random.randn(4) * 30 + 30,\n","                np.random.randn(4) * 30 + 30,\n","                np.random.randn(4) * 30 + 30,\n","                np.random.randn(4) * 30 + 30,\n","            ], dtype=torch.float)\n","\n","            # Ensure energies are positive\n","            x[:, 3] = torch.abs(x[:, 3])\n","\n","            # Fully connected graph: all particles connected to each other\n","            # This could be changed later to make two particles connect to the Z,\n","            #  but for now we don't assume we know the correct pairing.\n","            edges = []\n","            for i in range(num_particles):\n","                for j in range(num_particles):\n","                    if i != j:\n","                        edges.append([i, j])\n","            edge_index = torch.tensor(edges, dtype=torch.long).t()\n","\n","        # Create PyTorch Geometric Data object\n","        data = Data(x=x, edge_index=edge_index, y=y)\n","        data_list.append(data)\n","\n","    return data_list\n","\n"],"metadata":{"id":"P9QidjlvK8d0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Implement the Graph Neural Network\n","\n","We avoided [the `torch.geometric` library](https://pytorch-geometric.readthedocs.io/en/latest/) for our very simple spring-mass system, but let's dive in and use it here, as an example of how to leverage the pre-built features.\n","\n","Some key ideas for `torch.geometric`:\n","- `forward` defines the passage of data through the network\n","- message passing is simplified in this example\n","- aggregation is simple sum of edges on the nodes\n","\n"],"metadata":{"id":"_NgLixwMLqua"}},{"cell_type":"code","source":["!pip install torch-geometric"],"metadata":{"id":"HiGoy_glOveB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["There is one very annoying thing about `torch.nn.functional`: it does not use `ReLU`, instead it uses `relu`.\n"],"metadata":{"id":"16upVAKyUGX0"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","from torch_geometric.nn import MessagePassing, global_mean_pool\n","\n","class SimpleParticleGNN(MessagePassing):\n","    # The MessagePassing base class takes care of everything after you\n","    # define the message and update functions.\n","\n","    def __init__(self, node_features, hidden_dim, num_classes):\n","        super().__init__(aggr='add') # simplest aggregation\n","\n","        # input particle features are (px, py, pz, energy)\n","        self.node_encoder = nn.Linear(node_features, hidden_dim)\n","\n","        # message passing layers - update particle representations\n","        #  before classification\n","        self.mp_layer1 = nn.Linear(hidden_dim, hidden_dim)\n","        self.mp_layer2 = nn.Linear(hidden_dim, hidden_dim)\n","\n","        # Graph-level classification head\n","        self.classifier = nn.Sequential(\n","            nn.Linear(hidden_dim, hidden_dim),\n","            nn.ReLU(),\n","            nn.Linear(hidden_dim, num_classes)\n","        )\n","\n","    def forward(self, x, edge_index, batch):\n","        \"\"\"\n","        Build up the forward pass through the model, defining the organization of the layers.\n","        Args:\n","            x: Node features [num_nodes, node_features] - particle 4-momenta\n","            edge_index: Graph connectivity [2, num_edges] - which particles are connected\n","            batch: Batch assignment [num_nodes] - which graph each particle belongs to\n","        \"\"\"\n","        # Step 1: Encode features\n","        x = F.relu(self.node_encoder(x))\n","        # x.shape: [4, 64] - now 64-dim representations\n","\n","        # Step 2: Message passing round 1\n","        x = self.propagate(edge_index, x=x)\n","        # Each particle aggregates info from 3 neighbors (sum aggregation)\n","        # Particle 0 now knows about particles 1, 2, 3\n","\n","        x = F.relu(self.mp_layer1(x))\n","        # x.shape: still [4, 64]\n","\n","        # Step 3: Message passing round 2\n","        x = self.propagate(edge_index, x=x)\n","        # Second-order neighbors: particle 0 now has info from 2-hop away\n","        x = F.relu(self.mp_layer2(x))\n","        # x.shape: still [4, 64]\n","\n","        # Step 4: Global pooling\n","        x = global_mean_pool(x, batch)\n","        # x.shape: [1, 64] - one embedding for the entire event\n","\n","        # Step 5: Classification\n","        out = self.classifier(x)\n","        # out.shape: [1, 2] - logits for [Z, Higgs]\n","        return out\n","\n","    def message(self, x_j):\n","        \"\"\"\n","        Define how messages are created from neighbor particles.\n","        x_j contains features of neighbor particles.\n","        \"\"\"\n","        return x_j  # simply pass neighbor features without changes\n","\n","    def update(self, aggr_out):\n","        \"\"\"\n","        Define how aggregated messages update particle features.\n","        We want to return aggr_out, which is the sum of all neighbor messages.\n","        \"\"\"\n","        return aggr_out\n"],"metadata":{"id":"ic03fckvLVn1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we have to define the training options\n","- for a single training epoch\n","- define forward pass and loss function\n","\n","And testing options\n","- define output prediction for testing"],"metadata":{"id":"gcd5Ou-YValI"}},{"cell_type":"code","source":["def train_model(model, train_loader, optimizer, device):\n","    # This function will train for one epoch only\n","    model.train()\n","    total_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    for data in train_loader:\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        out = model(data.x, data.edge_index, data.batch)\n","        loss = F.cross_entropy(out, data.y)\n","\n","        # Backward pass\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Track metrics\n","        total_loss += loss.item() * data.num_graphs\n","        pred = out.argmax(dim=1)\n","        correct += (pred == data.y).sum().item()\n","        total += data.num_graphs\n","\n","    return total_loss / total, correct / total\n","\n","\n","def test_model(model, test_loader, device):\n","\n","    model.eval()\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for data in test_loader:\n","            data = data.to(device)\n","            out = model(data.x, data.edge_index, data.batch)\n","            pred = out.argmax(dim=1)\n","            correct += (pred == data.y).sum().item()\n","            total += data.num_graphs\n","\n","    return correct / total"],"metadata":{"id":"3m3dd387OQFj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Finally, with all of the functions defined, we are ready to run them all together.\n","\n"],"metadata":{"id":"UavXKsUkVtJI"}},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\\n\")\n","\n","print(\"Generating synthetic decay data...\")\n","z_decays = create_simulated_decay_data(num_events=500, decay_type='Z')\n","higgs_decays = create_simulated_decay_data(num_events=500, decay_type='Higgs')\n","\n","# Combine and split into train/test\n","all_data = z_decays + higgs_decays\n","np.random.shuffle(all_data)\n","\n","train_data = all_data[:800]\n","test_data = all_data[800:]\n","\n","print(f\"Training samples: {len(train_data)}\")\n","print(f\"Test samples: {len(test_data)}\")\n","print(f\"Example Z decay: {z_decays[0].x.shape[0]} particles\")\n","print(f\"Example Higgs decay: {higgs_decays[0].x.shape[0]} particles\\n\")\n","\n","# Create data loaders (batches multiple graphs together)\n","train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n","\n","# Initialize model\n","model = SimpleParticleGNN(\n","    node_features=4,      # [px, py, pz, energy]\n","    hidden_dim=64,        # Hidden representation size\n","    num_classes=2         # Z or Higgs\n",").to(device)\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n","\n","print(\"Training model...\")\n","\n","# Training loop\n","for epoch in range(50):\n","    train_loss, train_acc = train_model(model, train_loader, optimizer, device)\n","    test_acc = test_model(model, test_loader, device)\n","\n","    if (epoch + 1) % 10 == 0:\n","        print(f\"Epoch {epoch+1:3d} | \"\n","              f\"Train Loss: {train_loss:.4f} | \"\n","              f\"Train Acc: {train_acc:.4f} | \"\n","              f\"Test Acc: {test_acc:.4f}\")"],"metadata":{"id":"A3fRvkx1PGF2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Demonstrate inference on a few examples\n","print(\"Example Predictions:\")\n","print(\"=\"*60) # trick for formatting\n","model.eval()\n","with torch.no_grad():\n","    for i, data in enumerate(test_data[:5]):\n","        data = data.to(device)\n","        out = model(data.x, data.edge_index,\n","                   torch.zeros(data.num_nodes, dtype=torch.long, device=device))\n","        pred = out.argmax(dim=1).item()\n","        true_label = data.y.item()\n","        confidence = F.softmax(out, dim=1)[0]\n","\n","        decay_type = \"Z\" if true_label == 0 else \"Higgs\"\n","        pred_type = \"Z\" if pred == 0 else \"Higgs\"\n","\n","        print(f\"\\nEvent {i+1}:\")\n","        print(f\"  Particles: {data.num_nodes}\")\n","        print(f\"  True label: {decay_type}\")\n","        print(f\"  Predicted: {pred_type}\")\n","        print(f\"  Confidence: Z={confidence[0]:.3f}, Higgs={confidence[1]:.3f}\")\n","        print(f\"  {'✓ Correct' if pred == true_label else '✗ Incorrect'}\")"],"metadata":{"id":"UobNF7-EPm_g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The performance of this model is extremely good.\n","It is probably just learning to count the number of particles instead of learning the momentum correlations between particles.\n","\n","You can try generating a different dataset, perhaps with Z bosons vs. W bosons, to get more of a challenge."],"metadata":{"id":"__B04_txR_oI"}},{"cell_type":"code","source":[],"metadata":{"id":"3u1DsAABQIlL"},"execution_count":null,"outputs":[]}]}