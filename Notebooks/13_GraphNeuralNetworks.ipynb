{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Neural Networks\n",
        "\n",
        "In this notebook we give an example of a Graph Neural Network built on physics equations for a dynamic physical system.\n",
        "\n",
        "The GNN is built with PyTorch, but we write the layers out explicitly instead of using `torch_geometric`.\n",
        "\n",
        "## Spring-Mass System\n",
        "\n",
        "This system has 3 masses connected by springs in a 1-dimensional chain. This means mass 1 is connected to mass 2, and mass 2 is connected to mass 3, but mass 1 is not directly connected to mass 2.\n",
        "\n",
        "Our goal is to train the GNN to predict the next velocities (actually the change in velocities $dv$, given a spring-mass configuration of positions and current velocities.\n",
        "\n",
        "## Generate training data\n",
        "\n",
        "First we will generate some random configurations for training.\n",
        "Note that these are *not* necessarily connected by time steps; these are simply random configurations and next velocities calculated from those configurations.\n"
      ],
      "metadata": {
        "id": "kCFUaVwdZ976"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ============================================\n",
        "# 1. GENERATE PHYSICS DATA\n",
        "# ============================================\n",
        "\n",
        "def generate_spring_system_data(n_samples=1000):\n",
        "    \"\"\"\n",
        "    Create a simple 1D chain: mass -- spring -- mass -- spring -- mass\n",
        "    We'll have 3 masses connected by 2 springs\n",
        "    n_samples is the number of samples to generate\n",
        "    For each sample, we throw random positions and velocities\n",
        "    and calculate the next velocities. We are not evolving in time!\n",
        "    \"\"\"\n",
        "    data = []\n",
        "\n",
        "    for _ in range(n_samples):\n",
        "        # Random initial positions (displacements from equilibrium)\n",
        "        # There are 3 masses, but each has only an x coordinate\n",
        "        positions = torch.randn(3) * 0.5\n",
        "\n",
        "        # Random velocities\n",
        "        velocities = torch.randn(3) * 0.3\n",
        "\n",
        "        # Spring constants (all equal for simplicity)\n",
        "        k = 1.0\n",
        "        # Mass (all equal)\n",
        "        m = 1.0\n",
        "        # Time step\n",
        "        dt = 0.01\n",
        "\n",
        "        # Calculate forces: F = -k * (x_i - x_j) for connected masses\n",
        "        forces = torch.zeros(3)\n",
        "        forces[0] = -k * (positions[0] - positions[1])  # spring 0-1\n",
        "        forces[1] = -k * (positions[1] - positions[0]) - k * (positions[1] - positions[2])  # springs from both sides\n",
        "        forces[2] = -k * (positions[2] - positions[1])  # spring 1-2\n",
        "\n",
        "        # ADD NOISE later to make it more realistic\n",
        "        #forces += torch.randn(3) * 0.1  # Measurement noise or external perturbations\n",
        "\n",
        "        # Acceleration from F = ma\n",
        "        accelerations = forces / m\n",
        "\n",
        "        # Next velocities (Euler integration)\n",
        "        next_velocities = velocities + accelerations * dt\n",
        "\n",
        "        data.append({\n",
        "            'positions': positions,\n",
        "            'velocities': velocities,\n",
        "            'next_velocities': next_velocities,\n",
        "            'edges': torch.tensor([[0, 1], [1, 0], [1, 2], [2, 1]], dtype=torch.long).T  # bidirectional edges\n",
        "        })\n",
        "\n",
        "    return data\n",
        "\n",
        "# Test this generator by looking at the first data sample\n",
        "vis_data = generate_spring_system_data(n_samples=10)\n",
        "print(vis_data[0])"
      ],
      "metadata": {
        "id": "oaihy25BAoQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output is a series of positions, velocities, and next_velocities.\n",
        "\n",
        "It is always a good idea to plot the data, so that we can see what it looks like."
      ],
      "metadata": {
        "id": "krvxWgT5bMDX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71cb5275"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract all positions from vis_data\n",
        "all_positions = []\n",
        "for sample in vis_data:\n",
        "    # Convert each position tensor to numpy array\n",
        "    all_positions.append(sample['positions'].numpy())\n",
        "\n",
        "all_positions = np.array(all_positions) # Shape will be (n_samples, 3)\n",
        "\n",
        "# Plotting the positions of the 3 masses as a function of time\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i in range(all_positions.shape[1]): # Iterate through the 3 position dimensions\n",
        "    plt.plot(all_positions[:, i], label=f'Mass {i+1} Position')\n",
        "\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Position Value')\n",
        "plt.title('Random Positions of 3 Masses Across Samples')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember that these are completely random positions, not time evolution of positions. (They really shouldn't even be connected with a line.)"
      ],
      "metadata": {
        "id": "-sw2S_7ucM6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up network\n",
        "\n",
        "The GNN is very simple: just one hidden layer is enough to learn this linear physics $F=-k (x_1-x_\n",
        "2)$.\n",
        "\n",
        "The key is the message passing step.\n",
        "\n",
        "What is being learned by this network?"
      ],
      "metadata": {
        "id": "oMh75BpXdExo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 2. GRAPH NEURAL NETWORK\n",
        "# ============================================\n",
        "\n",
        "class SpringGNN(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple GNN that learns spring dynamics\n",
        "    Key idea: Each node (mass) gets information from its neighbors\n",
        "    through the edges (springs) to predict its next state.\n",
        "    The goal is to predict what the change in velocities will be.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden_dim=32):\n",
        "        super().__init__()\n",
        "\n",
        "        # Node features: position + velocity = 2 features per node\n",
        "        # Edge network: processes information flowing along edges\n",
        "        self.edge_mlp = nn.Sequential(\n",
        "            nn.Linear(4, hidden_dim),  # 2 features from source + 2 from target\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "\n",
        "        # Node update network: aggregates edge messages and updates node state\n",
        "        self.node_mlp = nn.Sequential(\n",
        "            nn.Linear(2 + hidden_dim, hidden_dim),  # original features + aggregated messages\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 1)  # predict change in velocity\n",
        "        )\n",
        "\n",
        "    def forward(self, positions, velocities, edges):\n",
        "        \"\"\"\n",
        "        positions: [n_nodes] - current positions\n",
        "        velocities: [n_nodes] - current velocities\n",
        "        edges: [2, n_edges] - edge connectivity\n",
        "        \"\"\"\n",
        "        n_nodes = positions.shape[0]\n",
        "\n",
        "        # Combine position and velocity as node features\n",
        "        node_features = torch.stack([positions, velocities], dim=1)  # [n_nodes, 2]\n",
        "\n",
        "        # MESSAGE PASSING STEP\n",
        "        # For each edge, create a message based on source and target features\n",
        "        source_nodes = edges[0]\n",
        "        target_nodes = edges[1]\n",
        "\n",
        "        # Get features of connected nodes\n",
        "        source_features = node_features[source_nodes]  # [n_edges, 2]\n",
        "        target_features = node_features[target_nodes]  # [n_edges, 2]\n",
        "\n",
        "        # Create edge messages by processing both node features\n",
        "        edge_features = torch.cat([source_features, target_features], dim=1)  # [n_edges, 4]\n",
        "        edge_messages = self.edge_mlp(edge_features)  # [n_edges, hidden_dim]\n",
        "\n",
        "        # AGGREGATION STEP\n",
        "        # Sum messages arriving at each node\n",
        "        aggregated = torch.zeros(n_nodes, edge_messages.shape[1])\n",
        "        for i in range(edges.shape[1]):\n",
        "            target = target_nodes[i]\n",
        "            aggregated[target] += edge_messages[i]\n",
        "\n",
        "        # UPDATE STEP\n",
        "        # Combine original features with aggregated messages to predict update\n",
        "        combined = torch.cat([node_features, aggregated], dim=1)  # [n_nodes, 2 + hidden_dim]\n",
        "        velocity_updates = self.node_mlp(combined).squeeze()  # [n_nodes]\n",
        "\n",
        "        return velocity_updates\n"
      ],
      "metadata": {
        "id": "CpCrcGHuAxxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "Now we present the random training data to the GNN for training.\n",
        "The loss function is actually the change in velocity $dv$.\n",
        "\n",
        "*Warning*: this is pretty slow to train, even with GPU."
      ],
      "metadata": {
        "id": "GWgf0hKBdeRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 3. TRAINING\n",
        "# ============================================\n",
        "\n",
        "# Generate data\n",
        "print(\"Generating training data...\")\n",
        "train_data = generate_spring_system_data(1000)\n",
        "test_data = generate_spring_system_data(200)\n",
        "\n",
        "# Initialize model\n",
        "model = SpringGNN(hidden_dim=32)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "print(\"\\nTraining GNN...\")\n",
        "n_epochs = 100\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    for sample in train_data:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        predicted_dv = model(sample['positions'], sample['velocities'], sample['edges'])\n",
        "\n",
        "        # True change in velocity\n",
        "        true_dv = sample['next_velocities'] - sample['velocities']\n",
        "\n",
        "        # Loss\n",
        "        loss = F.mse_loss(predicted_dv, true_dv)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {total_loss/len(train_data):.6f}\")\n"
      ],
      "metadata": {
        "id": "DgFMQA7pA2my"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The evaluation on the test data compares the expected $dv$ with the predicted $dv$. The result is almost perfect because it is just a linear function that is easily learned."
      ],
      "metadata": {
        "id": "JvbY8ABEdph4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 4. EVALUATION\n",
        "# ============================================\n",
        "\n",
        "print(\"\\nEvaluating on test set...\")\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for sample in test_data:\n",
        "        predicted_dv = model(sample['positions'], sample['velocities'], sample['edges'])\n",
        "        true_dv = sample['next_velocities'] - sample['velocities']\n",
        "        test_loss += F.mse_loss(predicted_dv, true_dv).item()\n",
        "\n",
        "print(f\"Test Loss: {test_loss/len(test_data):.6f}\")"
      ],
      "metadata": {
        "id": "CTAc24L6A64f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we visualize the predictions by evolving a random sample system forward in time to see if the GNN learned its kinematic behavior."
      ],
      "metadata": {
        "id": "jKMVhE0Id3Ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 5. VISUALIZE PREDICTIONS\n",
        "# ============================================\n",
        "\n",
        "# Pick a random test sample and simulate forward in time\n",
        "# by using the predicted change in velocities.\n",
        "sample = test_data[0]\n",
        "positions = sample['positions'].clone()\n",
        "velocities = sample['velocities'].clone()\n",
        "\n",
        "predicted_positions = [positions.numpy().copy()]\n",
        "true_positions = [positions.numpy().copy()]\n",
        "\n",
        "# Simulation parameters\n",
        "k, m, dt = 1.0, 1.0, 0.01\n",
        "n_steps = 500\n",
        "\n",
        "with torch.no_grad():\n",
        "    for step in range(n_steps):\n",
        "        # GNN prediction\n",
        "        dv_pred = model(positions, velocities, sample['edges'])\n",
        "        velocities_pred = velocities + dv_pred\n",
        "        positions = positions + velocities_pred * dt\n",
        "        predicted_positions.append(positions.numpy().copy())\n",
        "\n",
        "        # True physics (for comparison)\n",
        "        # These are the same equations we used to generate the data\n",
        "        if step == 0:\n",
        "            true_pos = sample['positions'].clone()\n",
        "            true_vel = sample['velocities'].clone()\n",
        "\n",
        "        forces = torch.zeros(3)\n",
        "        forces[0] = -k * (true_pos[0] - true_pos[1])\n",
        "        forces[1] = -k * (true_pos[1] - true_pos[0]) - k * (true_pos[1] - true_pos[2])\n",
        "        forces[2] = -k * (true_pos[2] - true_pos[1])\n",
        "\n",
        "        true_vel = true_vel + (forces / m) * dt\n",
        "        true_pos = true_pos + true_vel * dt\n",
        "        true_positions.append(true_pos.numpy().copy())\n",
        "\n",
        "predicted_positions = np.array(predicted_positions)\n",
        "true_positions = np.array(true_positions)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 4))\n",
        "for i in range(3):\n",
        "    plt.plot(predicted_positions[:, i], label=f'GNN Mass {i}', linestyle='--')\n",
        "    plt.plot(true_positions[:, i], label=f'True Mass {i}', alpha=0.7)\n",
        "\n",
        "plt.xlabel('Time Step')\n",
        "plt.ylabel('Position')\n",
        "plt.title('GNN vs True Physics: Spring-Mass System')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xgwdl7haAZEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis: what went wrong in the GNN?\n",
        "\n",
        "We trained the GNN to learn the `dv`, the change in velocities. This is a linear function when the time steps `dt` are very small. But after many steps, the true motion curves away from this simple linear prediction. (Think, for example of $dx = v\\ dt$ but with $v=at$ changing with time.)\n",
        "\n",
        "You can see that the GNN performs very well, until we run it for many steps and the error from the linear assumption accumulates.\n",
        "\n"
      ],
      "metadata": {
        "id": "R5exSJKGIQBl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Alternative GNN to learn acceleration\n",
        "\n",
        "In fact, the *acceleration* might be a more useful thing to learn. Let's write a GNN that will learn the acceleration of the system instead of the velocity change `dv`.\n",
        "\n",
        "Note that this will give a true linear system, unlike the velocity changes which accumulate. Therefore we don't need a very deep GNN to learn the physics of this system."
      ],
      "metadata": {
        "id": "TCfhm5BoJjL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 1. GENERATE PHYSICS DATA WITH ACCELERATIONS\n",
        "# ============================================\n",
        "\n",
        "def generate_spring_system_acc_data(n_samples=1000):\n",
        "    \"\"\"\n",
        "    Create a simple 1D chain: mass -- spring -- mass -- spring -- mass\n",
        "    We'll have 3 masses connected by 2 springs\n",
        "    n_samples is the number of time steps to generate\n",
        "    \"\"\"\n",
        "    data = []\n",
        "\n",
        "    for _ in range(n_samples):\n",
        "        # Random initial positions (displacements from equilibrium)\n",
        "        # There are 3 masses, but each has only an x coordinate\n",
        "        positions = torch.randn(3) * 0.5\n",
        "\n",
        "        # Random velocities\n",
        "        velocities = torch.randn(3) * 0.3\n",
        "\n",
        "        # Spring constants (all equal for simplicity)\n",
        "        k = 1.0\n",
        "        # Mass (all equal)\n",
        "        m = 1.0\n",
        "        # Time step\n",
        "        dt = 0.01\n",
        "\n",
        "        # Calculate forces: F = -k * (x_i - x_j) for connected masses\n",
        "        forces = torch.zeros(3)\n",
        "        forces[0] = -k * (positions[0] - positions[1])  # spring 0-1\n",
        "        forces[1] = -k * (positions[1] - positions[0]) - k * (positions[1] - positions[2])  # springs from both sides\n",
        "        forces[2] = -k * (positions[2] - positions[1])  # spring 1-2\n",
        "\n",
        "        # ADD NOISE later to make it more realistic\n",
        "        #forces += torch.randn(3) * 0.1  # Measurement noise or external perturbations\n",
        "\n",
        "        # Acceleration from F = ma\n",
        "        accelerations = forces / m\n",
        "\n",
        "        data.append({\n",
        "            'positions': positions,\n",
        "            'velocities': velocities,\n",
        "            'accelerations': accelerations,  # Target is now acceleration\n",
        "            'edges': torch.tensor([[0, 1], [1, 0], [1, 2], [2, 1]], dtype=torch.long).T  # bidirectional edges\n",
        "        })\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "v5UCMO5kAjt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main difference in the GNN is that we will now update and learn accelerations instead of velocity changes."
      ],
      "metadata": {
        "id": "CxT3zghXONiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SpringGNN_Acc(nn.Module):\n",
        "    \"\"\"\n",
        "    A GNN that learns to predict ACCELERATION from current state\n",
        "    This is more physics-inspired: a = F/m, and F depends on relative positions\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden_dim=32):  # Even 32 might be overkill!\n",
        "        super().__init__()\n",
        "\n",
        "        # Edge network processes information about relative positions/velocities\n",
        "        # force (and acceleration) depends on RELATIVE position\n",
        "        self.edge_mlp = nn.Sequential(\n",
        "            nn.Linear(4, hidden_dim),  # 2 features from source + 2 from target\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "\n",
        "        # Node update network: predicts acceleration from aggregated edge info\n",
        "        self.node_mlp = nn.Sequential(\n",
        "            nn.Linear(2 + hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 1)  # predict acceleration\n",
        "        )\n",
        "\n",
        "    def forward(self, positions, velocities, edges):\n",
        "        \"\"\"Returns: predicted accelerations for each node\"\"\"\n",
        "        n_nodes = positions.shape[0]\n",
        "\n",
        "        # Node features\n",
        "        node_features = torch.stack([positions, velocities], dim=1)\n",
        "\n",
        "        # MESSAGE PASSING\n",
        "        source_nodes = edges[0]\n",
        "        target_nodes = edges[1]\n",
        "\n",
        "        source_features = node_features[source_nodes]\n",
        "        target_features = node_features[target_nodes]\n",
        "\n",
        "        # Edge messages encode relative information\n",
        "        edge_features = torch.cat([source_features, target_features], dim=1)\n",
        "        edge_messages = self.edge_mlp(edge_features)\n",
        "\n",
        "        # AGGREGATION\n",
        "        aggregated = torch.zeros(n_nodes, edge_messages.shape[1])\n",
        "        for i in range(edges.shape[1]):\n",
        "            target = target_nodes[i]\n",
        "            aggregated[target] += edge_messages[i]\n",
        "\n",
        "        # UPDATE\n",
        "        combined = torch.cat([node_features, aggregated], dim=1)\n",
        "        accelerations = self.node_mlp(combined).squeeze()\n",
        "\n",
        "        return accelerations"
      ],
      "metadata": {
        "id": "0g-cjnxhMx5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the training loss function has to be the acceleration instead of the change in velocities."
      ],
      "metadata": {
        "id": "FUWIu5J5eB3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 3. TRAINING\n",
        "# ============================================\n",
        "\n",
        "print(\"Generating training data...\")\n",
        "train_data = generate_spring_system_acc_data(2000)  # More data for better learning\n",
        "test_data = generate_spring_system_acc_data(200)\n",
        "\n",
        "model = SpringGNN_Acc(hidden_dim=32)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"\\nTraining GNN to predict acceleration...\")\n",
        "n_epochs = 100\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    for sample in train_data:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Predict acceleration\n",
        "        predicted_accel = model(sample['positions'], sample['velocities'], sample['edges'])\n",
        "        true_accel = sample['accelerations']\n",
        "\n",
        "        # Loss\n",
        "        loss = F.mse_loss(predicted_accel, true_accel)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {total_loss/len(train_data):.6f}\")\n",
        "\n",
        "# ============================================\n",
        "# 4. EVALUATION\n",
        "# ============================================\n",
        "\n",
        "print(\"\\nEvaluating on test set...\")\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for sample in test_data:\n",
        "        predicted_accel = model(sample['positions'], sample['velocities'], sample['edges'])\n",
        "        true_accel = sample['accelerations']\n",
        "        test_loss += F.mse_loss(predicted_accel, true_accel).item()\n",
        "\n",
        "print(f\"Test Loss: {test_loss/len(test_data):.6f}\")\n"
      ],
      "metadata": {
        "id": "UMIIYJ9RNXRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We repeat the simulation, this time with acceleration updates at each step."
      ],
      "metadata": {
        "id": "aQReyxW3eGZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 5. LONG-TERM SIMULATION (500 steps)\n",
        "# ============================================\n",
        "\n",
        "def simulate_with_gnn(model, initial_pos, initial_vel, edges, n_steps, dt):\n",
        "    \"\"\"\n",
        "    Simulate using GNN-predicted accelerations\n",
        "    \"\"\"\n",
        "    positions = initial_pos.clone()\n",
        "    velocities = initial_vel.clone()\n",
        "    trajectory = [positions.numpy().copy()]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n_steps):\n",
        "            # GNN predicts acceleration\n",
        "            accel = model(positions, velocities, edges)\n",
        "\n",
        "            # Physics integration\n",
        "            velocities = velocities + accel * dt\n",
        "            positions = positions + velocities * dt\n",
        "\n",
        "            trajectory.append(positions.numpy().copy())\n",
        "\n",
        "    return np.array(trajectory)\n",
        "\n",
        "def simulate_true_physics(initial_pos, initial_vel, n_steps, dt, k=1.0, m=1.0):\n",
        "    \"\"\"\n",
        "    Simulate using true physics equations instead of random data snapshots\n",
        "    like the training data\n",
        "    \"\"\"\n",
        "    positions = initial_pos.clone()\n",
        "    velocities = initial_vel.clone()\n",
        "    trajectory = [positions.numpy().copy()]\n",
        "\n",
        "    for _ in range(n_steps):\n",
        "        # True forces\n",
        "        forces = torch.zeros(3)\n",
        "        forces[0] = -k * (positions[0] - positions[1])\n",
        "        forces[1] = -k * (positions[1] - positions[0]) - k * (positions[1] - positions[2])\n",
        "        forces[2] = -k * (positions[2] - positions[1])\n",
        "\n",
        "        # Integration\n",
        "        accel = forces / m\n",
        "        velocities = velocities + accel * dt\n",
        "        positions = positions + velocities * dt\n",
        "\n",
        "        trajectory.append(positions.numpy().copy())\n",
        "\n",
        "    return np.array(trajectory)\n",
        "\n",
        "# Run simulation\n",
        "sample = test_data[0]\n",
        "# We need dt here to calculate positions from the accelerations.\n",
        "dt = 0.01\n",
        "n_steps = 500\n",
        "\n",
        "print(\"\\nRunning 500-step simulation...\")\n",
        "gnn_trajectory = simulate_with_gnn(model, sample['positions'], sample['velocities'],\n",
        "                                    sample['edges'], n_steps, dt)\n",
        "true_trajectory = simulate_true_physics(sample['positions'], sample['velocities'],\n",
        "                                        n_steps, dt)\n",
        "print(\"done!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "uGgEpn_vO2Zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 6. VISUALIZATION\n",
        "# ============================================\n",
        "\n",
        "plt.figure(figsize=(10, 6)) # Create a single figure\n",
        "\n",
        "# Plot all trajectories on the single figure\n",
        "for i in range(3):\n",
        "    plt.plot(gnn_trajectory[:, i], label=f'GNN Mass {i}', linestyle='--', linewidth=2)\n",
        "    plt.plot(true_trajectory[:, i], label=f'True Mass {i}', alpha=0.7, linewidth=2)\n",
        "\n",
        "plt.xlabel('Time Step', fontsize=11)\n",
        "plt.ylabel('Position', fontsize=11)\n",
        "plt.title('GNN vs True Physics: 500 Time Steps', fontsize=12, fontweight='bold')\n",
        "plt.legend(fontsize=10, ncol=3)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IdV4kVcUPRU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LYS6I8vpQ08K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}